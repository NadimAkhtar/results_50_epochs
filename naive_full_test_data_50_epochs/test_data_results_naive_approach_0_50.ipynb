{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_data_results_naive_approach_0_50.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAkjGOyqhlxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2bbb2ba-4a86-4bab-ce2d-55a995c5e084"
      },
      "source": [
        "! pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "! pip install seqeval\n",
        "! pip install sklearn_crfsuite\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from math import nan\n",
        "from future.utils import iteritems\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "import keras as k\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#loading train data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df=pd.read_csv('/content/drive//My Drive/entity_train.csv')\n",
        "\n",
        "df1=df[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1[df1['type']=='entity']  #We take only the entities i.e. removing the text and relation types\n",
        "\n",
        "df1=df1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "#loading test data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dftest=pd.read_csv('/content/drive//My Drive/entity_test.csv')\n",
        "\n",
        "dftest1=dftest[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1[dftest1['type']=='entity']  #We take only the entities i.e. removing the text and relation\n",
        "\n",
        "dftest1=dftest1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "###creating sentence id\n",
        "\n",
        "#for train data\n",
        "\n",
        "index_train=df1.index\n",
        "\n",
        "\n",
        "seq_train=[]\n",
        "seq_train.append(df1['sentence_idx'][index_train[0]])\n",
        "for i in range(1,len(index_train)):\n",
        "  seq_train.append(df1['sentence_idx'][index_train[i]]-df1['sentence_idx'][index_train[i-1]])\n",
        "len(seq_train)\n",
        "\n",
        "\n",
        "neg_ind_train=[]\n",
        "for i in range(len(seq_train)):\n",
        "  if seq_train[i]<0:\n",
        "    seq_train[i]=1\n",
        "    neg_ind_train.append(i)\n",
        "\n",
        "df1=df1.assign(ind_train=seq_train)\n",
        "sen_id=df1['ind_train'].cumsum()\n",
        "df1=df1.assign(sentence_idx=sen_id)\n",
        "df1=df1.drop('ind_train',1)\n",
        "df1=df1.dropna()\n",
        "\n",
        "#creating sentence id for test data\n",
        "\n",
        "index_test=dftest1.index\n",
        "\n",
        "\n",
        "seq_test=[]\n",
        "seq_test.append(dftest1['sentence_idx'][index_test[0]])\n",
        "for i in range(1,len(index_test)):\n",
        "  seq_test.append(dftest1['sentence_idx'][index_test[i]]-dftest1['sentence_idx'][index_test[i-1]])\n",
        "len(seq_test)\n",
        "\n",
        "\n",
        "neg_ind_test=[]\n",
        "for i in range(len(seq_test)):\n",
        "  if seq_test[i]<0:\n",
        "    seq_test[i]=1\n",
        "    neg_ind_test.append(i)\n",
        "\n",
        "dftest1=dftest1.assign(ind_test=seq_test)\n",
        "sen_id=dftest1['ind_test'].cumsum()\n",
        "dftest1=dftest1.assign(sentence_idx=sen_id)\n",
        "dftest1=dftest1.drop('ind_test',1)\n",
        "dftest1=dftest1.dropna()\n",
        "\n",
        "#Split test data into 2 half\n",
        "test_sp1, test_sp2 = train_test_split(dftest1, test_size=0.5,random_state=123)\n",
        "dfdev1, test_sp = train_test_split(test_sp2, test_size=0.5,random_state=123)\t#Split other half test data into dev and test data\n",
        "dfdev1=dfdev1.sort_index(axis=0)\n",
        "test_sp=test_sp.sort_index(axis=0)\n",
        "dftest1=test_sp\n",
        "\n",
        "#Taking only required tags and the rest renamed as others 'O'\n",
        "tag_req=['diap','fndg','lbpr','lbtr']\n",
        "df2=df1[df1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_train=df2.index\n",
        "\n",
        "for i in df1.index:\n",
        "  if i not in req_train:\n",
        "    df1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in df1.tag[i]:\n",
        "      df1.tag[i]='O'\n",
        "\n",
        "dftest2=dftest1[dftest1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test=dftest2.index\n",
        "\n",
        "for i in dftest1.index:\n",
        "  if i not in req_test:\n",
        "    dftest1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest1.tag[i]:\n",
        "      dftest1.tag[i]='O'\n",
        "\n",
        "dfdev2=dfdev1[dfdev1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_dev=dfdev2.index\n",
        "\n",
        "for i in dfdev1.index:\n",
        "  if i not in req_dev:\n",
        "    dfdev1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dfdev1.tag[i]:\n",
        "      dfdev1.tag[i]='O'\n",
        "\n",
        "#BIO-tagging For Train Data\n",
        "temp01=pd.DataFrame(df1.word.str.split().tolist(), index=df1['sentence_idx']).stack()\n",
        "d1 = temp01.index\n",
        "t1 = []\n",
        "for i in range(len(d1)):\n",
        "  if d1[i][1] == 0:\n",
        "    t1.append('B-')\n",
        "  else:\n",
        "    t1.append('I-')\n",
        "temp01 = temp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp01.columns = ['word','sentence_idx']\n",
        "temp01=temp01[['sentence_idx','word']]\n",
        "temp01=temp01.assign(bio_tr=t1)\n",
        "\n",
        "temp02=pd.DataFrame(df1.word.str.split().tolist(), index=df1['tag']).stack()\n",
        "temp02 = temp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp02.columns = ['word','tag']\n",
        "\n",
        "temp01[\"tag\"] = temp01[\"bio_tr\"].astype(str) + temp02[\"tag\"]\n",
        "del temp01['bio_tr']\n",
        "temp01['tag']=temp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "df1=temp01\n",
        "\n",
        "#BIO-tagging For Test Data\n",
        "temp_test01=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['sentence_idx']).stack()\n",
        "d1_test = temp_test01.index\n",
        "t1_test = []\n",
        "for i in range(len(d1_test)):\n",
        "  if d1_test[i][1] == 0:\n",
        "    t1_test.append('B-')\n",
        "  else:\n",
        "    t1_test.append('I-')\n",
        "temp_test01 = temp_test01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test01.columns = ['word','sentence_idx']\n",
        "temp_test01=temp_test01[['sentence_idx','word']]\n",
        "temp_test01=temp_test01.assign(bio_te=t1_test)\n",
        "\n",
        "temp_test02=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['tag']).stack()\n",
        "temp_test02 = temp_test02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test02.columns = ['word','tag']\n",
        "\n",
        "temp_test01[\"tag\"] = temp_test01[\"bio_te\"].astype(str) + temp_test02[\"tag\"]\n",
        "del temp_test01['bio_te']\n",
        "temp_test01['tag']=temp_test01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest1=temp_test01\n",
        "\n",
        "#BIO-tagging For dev Data\n",
        "temp_dev01=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['sentence_idx']).stack()\n",
        "d1_dev = temp_dev01.index\n",
        "t1_dev = []\n",
        "for i in range(len(d1_dev)):\n",
        "  if d1_dev[i][1] == 0:\n",
        "    t1_dev.append('B-')\n",
        "  else:\n",
        "    t1_dev.append('I-')\n",
        "temp_dev01 = temp_dev01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_dev01.columns = ['word','sentence_idx']\n",
        "temp_dev01=temp_dev01[['sentence_idx','word']]\n",
        "temp_dev01=temp_dev01.assign(bio_te=t1_dev)\n",
        "\n",
        "temp_dev02=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['tag']).stack()\n",
        "temp_dev02 = temp_dev02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_dev02.columns = ['word','tag']\n",
        "\n",
        "temp_dev01[\"tag\"] = temp_dev01[\"bio_te\"].astype(str) + temp_dev02[\"tag\"]\n",
        "del temp_dev01['bio_te']\n",
        "temp_dev01['tag']=temp_dev01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dfdev1=temp_dev01\n",
        "\n",
        "train=df1\n",
        "test=dftest1\n",
        "dev=dfdev1\n",
        "\n",
        "#Define Sentence Getter\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "#Sentence getter for train\n",
        "getter_train = SentenceGetter(train)\n",
        "sentences_train = getter_train.sentences\n",
        "\n",
        "#Sentence getter for test\n",
        "getter_test = SentenceGetter(test)\n",
        "sentences_test = getter_test.sentences\n",
        "\n",
        "#Sentence getter for dev\n",
        "getter_dev = SentenceGetter(dev)\n",
        "sentences_dev = getter_dev.sentences\n",
        "\n",
        "##formation of words and tags\n",
        "\n",
        "#for train\n",
        "\n",
        "words_train = list(set(train[\"word\"].values))\n",
        "n_words_train = len(words_train)\n",
        "\n",
        "tags_train = []\n",
        "for tag in set(train[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train.append('unk')\n",
        "    else:\n",
        "        tags_train.append(tag)\n",
        "n_tags_train = len(tags_train)\n",
        "\n",
        "#for test\n",
        "words_test = list(set(test[\"word\"].values))\n",
        "n_words_test = len(words_test)\n",
        "\n",
        "tags_test = []\n",
        "for tag in set(test[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_test.append('unk')\n",
        "    else:\n",
        "        tags_test.append(tag)\n",
        "n_tags_test = len(tags_test)\n",
        "\n",
        "#for dev\n",
        "words_dev = list(set(dev[\"word\"].values))\n",
        "n_words_dev = len(words_dev)\n",
        "\n",
        "tags_dev = []\n",
        "for tag in set(dev[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_dev.append('unk')\n",
        "    else:\n",
        "        tags_dev.append(tag)\n",
        "n_tags_dev = len(tags_dev)\n",
        "\n",
        "#taking union of train, dev and test\n",
        "\n",
        "words_all = list(set().union(words_train,words_test,words_dev))\n",
        "n_words_all = len(words_all)\n",
        "\n",
        "tags_all = list(set().union(tags_train,tags_test,tags_dev))\n",
        "n_tags_all = len(tags_all)\n",
        "\n",
        "##formation of word2id, tag2id and id2tag\n",
        "\n",
        "#for all union of train and test\n",
        "word2idx_all = {w: i for i, w in enumerate(words_all)}\n",
        "tag2idx_all = {t: i for i, t in enumerate(tags_all)}\n",
        "idx2tag_all = {v: k for k, v in iteritems(tag2idx_all)}\n",
        "\n",
        "maxlen_all = max(max([len(s) for s in sentences_train]),max([len(s) for s in sentences_test]),max([len(s) for s in sentences_dev]))\n",
        "\n",
        "##vectorisation\n",
        "\n",
        "#for train\n",
        "\n",
        "maxlen_train = max([len(s) for s in sentences_train])\n",
        "\n",
        "X_train = [[word2idx_all[w[0]] for w in s] for s in sentences_train]\n",
        "X_train = pad_sequences(maxlen=maxlen_all, sequences=X_train, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train = [[tag2idx_all[w[1]] for w in s] for s in sentences_train]\n",
        "y_train = pad_sequences(maxlen=maxlen_all, sequences=y_train, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train = [to_categorical(i, num_classes=n_tags_all) for i in y_train]\n",
        "\n",
        "\n",
        "#for test\n",
        "maxlen_test = max([len(s) for s in sentences_test])\n",
        "\n",
        "X_test = [[word2idx_all[w[0]] for w in s] for s in sentences_test]\n",
        "X_test = pad_sequences(maxlen=maxlen_all, sequences=X_test, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_test = [[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "y_test = pad_sequences(maxlen=maxlen_all, sequences=y_test, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_test = [to_categorical(i, num_classes=n_tags_all) for i in y_test]\n",
        "\n",
        "#for dev\n",
        "maxlen_dev = max([len(s) for s in sentences_dev])\n",
        "\n",
        "X_dev = [[word2idx_all[w[0]] for w in s] for s in sentences_dev]\n",
        "X_dev = pad_sequences(maxlen=maxlen_all, sequences=X_dev, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_dev = [[tag2idx_all[w[1]] for w in s] for s in sentences_dev]\n",
        "y_dev = pad_sequences(maxlen=maxlen_all, sequences=y_dev, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_dev = [to_categorical(i, num_classes=n_tags_all) for i in y_dev]\n",
        "\n",
        "##MODEL\n",
        "\n",
        "input = Input(shape=(max(X_train.shape[1],X_dev.shape[1],X_test.shape[1]),))\n",
        "word_embedding_size = 180\n",
        "\n",
        "# Embedding Layer\n",
        "model = Embedding(input_dim=n_words_all, output_dim=word_embedding_size, input_length=max(X_train.shape[1],X_dev.shape[1],X_test.shape[1]))(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model = Bidirectional(LSTM(units=word_embedding_size, \n",
        "                           return_sequences=True, \n",
        "                           dropout=0.5, \n",
        "                           recurrent_dropout=0.5, \n",
        "                           kernel_initializer=k.initializers.he_normal()))(model)\n",
        "model = LSTM(units=word_embedding_size * 2, \n",
        "             return_sequences=True, \n",
        "             dropout=0.5, \n",
        "             recurrent_dropout=0.5, \n",
        "             kernel_initializer=k.initializers.he_normal())(model)\n",
        "\n",
        "# TimeDistributed Layer\n",
        "model = TimeDistributed(Dense(n_tags_all, activation=\"relu\"))(model)  \n",
        "\n",
        "# CRF Layer\n",
        "crf = CRF(n_tags_all)\n",
        "\n",
        "out = crf(model)  # output\n",
        "model = Model(input, out)\n",
        "\n",
        "##FIT MODEL\n",
        "\n",
        "#Optimiser \n",
        "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Saving the best model only\n",
        "filepath=\"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-6d35wq8h\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-6d35wq8h\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=86181f3026ee4ae886707fe1007df789ddb122d19abba0d04505522be3431a25\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ns1v5i1e/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=8744f528aac0665c474485caf6146fb42c0629246712522565e44b2e818e9765\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (18,19,20,24,25,32,33,47,48,49,50,51,52,53,54,60,61,67,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (23,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:112: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:115: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:123: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:126: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 274)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 274, 180)          3492900   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 274, 360)          519840    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 274, 360)          1038240   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 274, 9)            3249      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 274, 9)            189       \n",
            "=================================================================\n",
            "Total params: 5,054,418\n",
            "Trainable params: 5,054,418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrBcODCWjnCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91dd7798-0293-4eb7-d377-012b165e31af"
      },
      "source": [
        "# Fit the best model\n",
        "history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=50, validation_data=(X_dev, np.array(y_dev)), verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 49758 samples, validate on 20655 samples\n",
            "Epoch 1/50\n",
            "49758/49758 [==============================] - 645s 13ms/step - loss: 0.1177 - crf_viterbi_accuracy: 0.9605 - accuracy: 0.0014 - val_loss: 0.0107 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9986\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99864, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/50\n",
            "49758/49758 [==============================] - 639s 13ms/step - loss: 0.0174 - crf_viterbi_accuracy: 0.9969 - accuracy: 0.0014 - val_loss: 0.0078 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9986\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.99864\n",
            "Epoch 3/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: 0.0147 - crf_viterbi_accuracy: 0.9969 - accuracy: 0.0014 - val_loss: 0.0064 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9986\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.99864\n",
            "Epoch 4/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: 0.0116 - crf_viterbi_accuracy: 0.9971 - accuracy: 0.0014 - val_loss: 0.0047 - val_crf_viterbi_accuracy: 0.9988 - val_accuracy: 0.9988\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99864 to 0.99880, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: 0.0081 - crf_viterbi_accuracy: 0.9977 - accuracy: 0.0014 - val_loss: 0.0038 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.99880 to 0.99898, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 6/50\n",
            "49758/49758 [==============================] - 639s 13ms/step - loss: 0.0065 - crf_viterbi_accuracy: 0.9980 - accuracy: 0.0014 - val_loss: 0.0031 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99898 to 0.99904, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 7/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: 0.0053 - crf_viterbi_accuracy: 0.9982 - accuracy: 0.0014 - val_loss: 0.0025 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99904 to 0.99911, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 8/50\n",
            "49758/49758 [==============================] - 643s 13ms/step - loss: 0.0040 - crf_viterbi_accuracy: 0.9984 - accuracy: 0.0014 - val_loss: 0.0019 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.99911 to 0.99917, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 9/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: 0.0029 - crf_viterbi_accuracy: 0.9986 - accuracy: 0.0014 - val_loss: 0.0013 - val_crf_viterbi_accuracy: 0.9993 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99917 to 0.99925, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 10/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: 0.0019 - crf_viterbi_accuracy: 0.9988 - accuracy: 0.0014 - val_loss: 7.6908e-04 - val_crf_viterbi_accuracy: 0.9993 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99925 to 0.99934, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 11/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: 0.0011 - crf_viterbi_accuracy: 0.9990 - accuracy: 0.0014 - val_loss: 3.2521e-04 - val_crf_viterbi_accuracy: 0.9994 - val_accuracy: 0.9994\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99934 to 0.99939, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 12/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: 4.0268e-04 - crf_viterbi_accuracy: 0.9991 - accuracy: 0.0014 - val_loss: -8.8275e-05 - val_crf_viterbi_accuracy: 0.9994 - val_accuracy: 0.9994\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.99939 to 0.99943, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 13/50\n",
            "49758/49758 [==============================] - 662s 13ms/step - loss: -2.2628e-04 - crf_viterbi_accuracy: 0.9992 - accuracy: 0.0014 - val_loss: -4.5275e-04 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99943 to 0.99945, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 14/50\n",
            "49758/49758 [==============================] - 645s 13ms/step - loss: -8.3189e-04 - crf_viterbi_accuracy: 0.9992 - accuracy: 0.0014 - val_loss: -8.7360e-04 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.99945 to 0.99947, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 15/50\n",
            "49758/49758 [==============================] - 647s 13ms/step - loss: -0.0014 - crf_viterbi_accuracy: 0.9993 - accuracy: 0.0014 - val_loss: -0.0013 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99947\n",
            "Epoch 16/50\n",
            "49758/49758 [==============================] - 648s 13ms/step - loss: -0.0019 - crf_viterbi_accuracy: 0.9993 - accuracy: 0.0014 - val_loss: -0.0017 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.99947 to 0.99948, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 17/50\n",
            "49758/49758 [==============================] - 643s 13ms/step - loss: -0.0024 - crf_viterbi_accuracy: 0.9994 - accuracy: 0.0014 - val_loss: -0.0021 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.99948 to 0.99949, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 18/50\n",
            "49758/49758 [==============================] - 641s 13ms/step - loss: -0.0029 - crf_viterbi_accuracy: 0.9994 - accuracy: 0.0014 - val_loss: -0.0024 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99949\n",
            "Epoch 19/50\n",
            "49758/49758 [==============================] - 643s 13ms/step - loss: -0.0033 - crf_viterbi_accuracy: 0.9994 - accuracy: 0.0014 - val_loss: -0.0028 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.99949 to 0.99949, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 20/50\n",
            "49758/49758 [==============================] - 644s 13ms/step - loss: -0.0038 - crf_viterbi_accuracy: 0.9995 - accuracy: 0.0014 - val_loss: -0.0032 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.99949 to 0.99951, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 21/50\n",
            "49758/49758 [==============================] - 646s 13ms/step - loss: -0.0043 - crf_viterbi_accuracy: 0.9995 - accuracy: 0.0014 - val_loss: -0.0034 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.99951 to 0.99952, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 22/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0047 - crf_viterbi_accuracy: 0.9995 - accuracy: 0.0014 - val_loss: -0.0039 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99952\n",
            "Epoch 23/50\n",
            "49758/49758 [==============================] - 644s 13ms/step - loss: -0.0051 - crf_viterbi_accuracy: 0.9995 - accuracy: 0.0014 - val_loss: -0.0042 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99952\n",
            "Epoch 24/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: -0.0055 - crf_viterbi_accuracy: 0.9995 - accuracy: 0.0014 - val_loss: -0.0045 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99952\n",
            "Epoch 25/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0060 - crf_viterbi_accuracy: 0.9996 - accuracy: 0.0014 - val_loss: -0.0050 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99952\n",
            "Epoch 26/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0064 - crf_viterbi_accuracy: 0.9996 - accuracy: 0.0014 - val_loss: -0.0053 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99952\n",
            "Epoch 27/50\n",
            "49758/49758 [==============================] - 643s 13ms/step - loss: -0.0068 - crf_viterbi_accuracy: 0.9996 - accuracy: 0.0014 - val_loss: -0.0056 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99952\n",
            "Epoch 28/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0072 - crf_viterbi_accuracy: 0.9996 - accuracy: 0.0014 - val_loss: -0.0060 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99952\n",
            "Epoch 29/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0076 - crf_viterbi_accuracy: 0.9996 - accuracy: 0.0014 - val_loss: -0.0063 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99952\n",
            "Epoch 30/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0080 - crf_viterbi_accuracy: 0.9996 - accuracy: 0.0014 - val_loss: -0.0068 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99952\n",
            "Epoch 31/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0084 - crf_viterbi_accuracy: 0.9996 - accuracy: 0.0014 - val_loss: -0.0070 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99952\n",
            "Epoch 32/50\n",
            "49758/49758 [==============================] - 641s 13ms/step - loss: -0.0088 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0074 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99952\n",
            "Epoch 33/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0092 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0077 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99952\n",
            "Epoch 34/50\n",
            "49758/49758 [==============================] - 643s 13ms/step - loss: -0.0096 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0081 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99952\n",
            "Epoch 35/50\n",
            "49758/49758 [==============================] - 644s 13ms/step - loss: -0.0100 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0084 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99952\n",
            "Epoch 36/50\n",
            "49758/49758 [==============================] - 641s 13ms/step - loss: -0.0104 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0088 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99952\n",
            "Epoch 37/50\n",
            "49758/49758 [==============================] - 641s 13ms/step - loss: -0.0107 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0090 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99952\n",
            "Epoch 38/50\n",
            "49758/49758 [==============================] - 646s 13ms/step - loss: -0.0111 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0095 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99952\n",
            "Epoch 39/50\n",
            "49758/49758 [==============================] - 639s 13ms/step - loss: -0.0115 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0098 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99952\n",
            "Epoch 40/50\n",
            "49758/49758 [==============================] - 642s 13ms/step - loss: -0.0119 - crf_viterbi_accuracy: 0.9997 - accuracy: 0.0014 - val_loss: -0.0102 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99952\n",
            "Epoch 41/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: -0.0123 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0106 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.99952\n",
            "Epoch 42/50\n",
            "49758/49758 [==============================] - 638s 13ms/step - loss: -0.0126 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0108 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.99952\n",
            "Epoch 43/50\n",
            "49758/49758 [==============================] - 641s 13ms/step - loss: -0.0130 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.99952\n",
            "Epoch 44/50\n",
            "49758/49758 [==============================] - 640s 13ms/step - loss: -0.0134 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.99952\n",
            "Epoch 45/50\n",
            "49758/49758 [==============================] - 641s 13ms/step - loss: -0.0138 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0119 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.99952\n",
            "Epoch 46/50\n",
            "49758/49758 [==============================] - 636s 13ms/step - loss: -0.0142 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0122 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.99952\n",
            "Epoch 47/50\n",
            "49758/49758 [==============================] - 632s 13ms/step - loss: -0.0145 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0126 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.99952\n",
            "Epoch 48/50\n",
            "49758/49758 [==============================] - 634s 13ms/step - loss: -0.0149 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0129 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.99952\n",
            "Epoch 49/50\n",
            "49758/49758 [==============================] - 635s 13ms/step - loss: -0.0153 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0133 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.99952\n",
            "Epoch 50/50\n",
            "49758/49758 [==============================] - 636s 13ms/step - loss: -0.0156 - crf_viterbi_accuracy: 0.9998 - accuracy: 0.0014 - val_loss: -0.0137 - val_crf_viterbi_accuracy: 0.9995 - val_accuracy: 0.9995\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.99952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBlx4_OVjsxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41db408c-2bbb-4716-cfe6-42c09856b80f"
      },
      "source": [
        "####PLOTS of loss and accuracy\n",
        "# Plot the graph \n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(accuracy) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
        "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "####FIT with the TEST data\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag_all[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "test_pred = model.predict(X_test, verbose=1)   \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = pred2label(y_test)\n",
        "\n",
        "#####REPORT of the fit\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
        "print(report)\n",
        "\n",
        "###Rest\n",
        "TP = {}\n",
        "TN = {}\n",
        "FP = {}\n",
        "FN = {}\n",
        "for tag in tag2idx_all.keys():\n",
        "    TP[tag] = 0\n",
        "    TN[tag] = 0    \n",
        "    FP[tag] = 0    \n",
        "    FN[tag] = 0    \n",
        "\n",
        "def accumulate_score_by_tag(gt, pred):\n",
        "    \"\"\"\n",
        "    For each tag keep stats\n",
        "    \"\"\"\n",
        "    if gt == pred:\n",
        "        TP[gt] += 1\n",
        "    elif gt != 'O' and pred == 'O':\n",
        "        FN[gt] +=1\n",
        "    elif gt == 'O' and pred != 'O':\n",
        "        FP[gt] += 1\n",
        "    else:\n",
        "        TN[gt] += 1\n",
        "\n",
        "for i, sentence in enumerate(X_test):\n",
        "    y_hat = np.argmax(test_pred[0], axis=-1)\n",
        "    gt = np.argmax(y_test[0], axis=-1)\n",
        "    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n",
        "        accumulate_score_by_tag(idx2tag_all[gt[idx]],tags_all[pred])\n",
        "\n",
        "for tag in tag2idx_all.keys():\n",
        "    print(f'tag:{tag}')    \n",
        "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
        "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20625/20625 [==============================] - 191s 9ms/step\n",
            "F1-score: 80.5%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-diap       0.87      0.85      0.86       878\n",
            "      B-fndg       0.81      0.80      0.80      2971\n",
            "      B-lbpr       0.87      0.89      0.88       443\n",
            "      B-lbtr       0.78      0.42      0.55        59\n",
            "      I-diap       0.85      0.79      0.82       470\n",
            "      I-fndg       0.77      0.65      0.71      2520\n",
            "      I-lbpr       0.77      0.83      0.80       208\n",
            "      I-lbtr       0.89      0.35      0.50        72\n",
            "           O       1.00      1.00      1.00   5643629\n",
            "\n",
            "    accuracy                           1.00   5651250\n",
            "   macro avg       0.85      0.73      0.77   5651250\n",
            "weighted avg       1.00      1.00      1.00   5651250\n",
            "\n",
            "tag:B-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:     20625\n",
            "tag:I-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:     20625\n",
            "tag:I-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:O\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:   5610000\n",
            "tag:B-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FffF7INlj_vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "train.to_csv('train.csv')\n",
        "dev.to_csv('dev.csv')\n",
        "test.to_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrOLbETQpF8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_unstructured=pd.DataFrame({'Test Tag':test_labels,'Predicted Tag':pred_labels})\n",
        "result_unstructured.to_csv('result_unstructured.csv')\n",
        "\n",
        "test_tag_temp01=[[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "test_tag_ind01=[]\n",
        "for i in range(len(test_tag_temp01)):\n",
        "  test_tag_ind01.append(len(test_tag_temp01[i]))\n",
        "\n",
        "predicted_tag_temp01=[]\n",
        "for i in range(len(pred_labels)):\n",
        "  predicted_tag_temp01.extend(pred_labels[i][:test_tag_ind01[i]])\n",
        "\n",
        "result=test.assign(predicted_tag=predicted_tag_temp01)\n",
        "result.to_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dewYRM2CqQi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}